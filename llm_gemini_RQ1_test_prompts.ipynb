{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mgetpass\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjson\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import tqdm\n",
    "import random\n",
    "    \n",
    "import google.generativeai as genai\n",
    "import textwrap\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyBnqN3HbBoAXwOQe7Tsg93_LeM-ah7UhFA\")\n",
    "gen_config = genai.types.GenerationConfig(temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3029356636.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    pip3 install pandas\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip3 install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-1.0-pro\n",
      "models/gemini-1.0-pro-001\n",
      "models/gemini-1.0-pro-latest\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-pro\n",
      "models/gemini-pro-vision\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "def to_markdown(text):\n",
    "    text = text.replace('â€¢', '  *')\n",
    "    return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
    "\n",
    "for m in genai.list_models():\n",
    "    if 'generateContent' in m.supported_generation_methods:\n",
    "        print(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-1.5-flash-latest', generation_config=gen_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "253"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_robot_data_dir = \"/data/llm_social_nav_transformed\"\n",
    "npys = []\n",
    "\n",
    "for bag_dir in os.listdir(real_robot_data_dir):\n",
    "    bag_dir_path = os.path.join(real_robot_data_dir, bag_dir)\n",
    "    if os.path.isdir(bag_dir_path):\n",
    "        npys_dir = os.path.join(bag_dir_path, \"npys\")\n",
    "        for npy_file in os.listdir(npys_dir):\n",
    "            npy_file_path = os.path.join(npys_dir, npy_file)\n",
    "            npys.append(npy_file_path)\n",
    "\n",
    "npys[:10]\n",
    "len(npys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(109, 9)\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "timesteps = 40\n",
    "\n",
    "df_rows = []\n",
    "for npy_file in npys:\n",
    "    sample_line = {}\n",
    "    example = np.load(npy_file, allow_pickle=True).item()\n",
    "    x = example['X']\n",
    "    y = example['y']\n",
    "    sample_line['id'] = npy_file\n",
    "    sample_line['participant'] = npy_file.split('/')[-3]\n",
    "    sample_line['goal'] = np.around(np.array(x['goal']), decimals=4)[-timesteps:, :2][::5]\n",
    "    sample_line['robot'] = np.around(np.array(example['robot']), decimals=4)[-timesteps:][::5]\n",
    "\n",
    "    if np.all(sample_line['goal'] == sample_line['goal'][0, :], axis=0).all() and np.all(sample_line['robot'] == sample_line['robot'][0, :], axis=0).all():\n",
    "        continue\n",
    "\n",
    "    nearby_array = np.around(np.array(x['nearby']), decimals=4)[-timesteps:][::5]\n",
    "    nearby_array = np.transpose(nearby_array, (1, 0, 2))\n",
    "\n",
    "    nearby_array_2d = nearby_array.reshape(nearby_array.shape[0], -1)\n",
    "    nearby_unique_rows, indices = np.unique(nearby_array_2d, axis=0, return_index=True)\n",
    "    nearby_array = nearby_unique_rows.reshape(-1, nearby_array.shape[1], nearby_array.shape[2])\n",
    "\n",
    "    ## change this so that it only checks if the first two indices == 0, rather than all indices\n",
    "    non_zero_nearby_array = []\n",
    "    # Iterate over the first dimension\n",
    "    for i in range(nearby_array.shape[0]):\n",
    "        # Check if the sub-array (40, 4) is all-zero\n",
    "        if not np.all(nearby_array[i] == 0):\n",
    "            non_zero_nearby_array.append(nearby_array[i])\n",
    "\n",
    "    non_zero_nearby_array = np.array(non_zero_nearby_array)\n",
    "    \n",
    "    sample_line['follower'] = np.around(np.array(x['follower']), decimals=4)[-timesteps:][::5]\n",
    "    sample_line['nearby'] = non_zero_nearby_array\n",
    "    sample_line['competence'] = y[0] + 1\n",
    "    sample_line['surprise'] = y[1] + 1\n",
    "    sample_line['intention'] = y[2] + 1\n",
    "    df_rows.append(sample_line)\n",
    "\n",
    "random.shuffle(df_rows)\n",
    "full_df = pd.DataFrame(df_rows)\n",
    "full_df.head()\n",
    "print(full_df.shape)\n",
    "print(len(full_df.participant.unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>participant</th>\n",
       "      <th>goal</th>\n",
       "      <th>robot</th>\n",
       "      <th>follower</th>\n",
       "      <th>nearby</th>\n",
       "      <th>competence</th>\n",
       "      <th>surprise</th>\n",
       "      <th>intention</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>/data/llm_social_nav_transformed/1713393153.56...</td>\n",
       "      <td>1713393153.5699694</td>\n",
       "      <td>[[-10.8086, -2.4583], [-10.9858, -2.3271], [-1...</td>\n",
       "      <td>[[0.7957, -0.6056], [0.8352, -0.55], [0.8352, ...</td>\n",
       "      <td>[[-0.5891, 0.4541, 0.8234, -0.5675], [-0.6961,...</td>\n",
       "      <td>[[[-0.8485, 3.1467, 0.7937, -0.6083], [-1.3945...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>/data/llm_social_nav_transformed/1713393153.56...</td>\n",
       "      <td>1713393153.5699694</td>\n",
       "      <td>[[-8.8254, -3.0157], [-8.6264, -3.1479], [-8.4...</td>\n",
       "      <td>[[-0.743, 0.6693], [-0.9038, 0.4279], [-0.9644...</td>\n",
       "      <td>[[0.3299, -0.5874, -0.6815, 0.7318], [0.4846, ...</td>\n",
       "      <td>[[[0.0, 0.0, -0.743, 0.6693], [0.0, 0.0, -0.90...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>/data/llm_social_nav_transformed/1715356072.57...</td>\n",
       "      <td>1715356072.5795307</td>\n",
       "      <td>[[-4.663, 0.2311], [-4.4146, 0.2084], [-4.1654...</td>\n",
       "      <td>[[-0.9999, 0.0118], [-0.9931, 0.1176], [-0.999...</td>\n",
       "      <td>[[0.8749, 0.1223, -0.9962, -0.0871], [0.8366, ...</td>\n",
       "      <td>[[[0.0, 0.0, -0.9999, 0.0118], [0.0, 0.0, -0.9...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>/data/llm_social_nav_transformed/1713302818.57...</td>\n",
       "      <td>1713302818.578851</td>\n",
       "      <td>[[-1.0906, -0.3883], [-1.0729, -0.3721], [-1.0...</td>\n",
       "      <td>[[-0.7821, -0.6232], [-0.3819, -0.9242], [0.11...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [...</td>\n",
       "      <td>[[[0.0, 0.0, -0.7821, -0.6232], [0.0, 0.0, -0....</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>/data/llm_social_nav_transformed/1715356072.57...</td>\n",
       "      <td>1715356072.5795307</td>\n",
       "      <td>[[-9.5907, 0.4219], [-9.5869, 0.4193], [-9.586...</td>\n",
       "      <td>[[0.6988, 0.7153], [0.3281, 0.9447], [-0.2224,...</td>\n",
       "      <td>[[-1.1599, -0.5517, -0.1146, -0.9934], [-0.706...</td>\n",
       "      <td>[[[-1.1599, -0.5517, -0.1146, -0.9934], [-0.70...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    id         participant  \\\n",
       "73   /data/llm_social_nav_transformed/1713393153.56...  1713393153.5699694   \n",
       "89   /data/llm_social_nav_transformed/1713393153.56...  1713393153.5699694   \n",
       "106  /data/llm_social_nav_transformed/1715356072.57...  1715356072.5795307   \n",
       "17   /data/llm_social_nav_transformed/1713302818.57...   1713302818.578851   \n",
       "28   /data/llm_social_nav_transformed/1715356072.57...  1715356072.5795307   \n",
       "\n",
       "                                                  goal  \\\n",
       "73   [[-10.8086, -2.4583], [-10.9858, -2.3271], [-1...   \n",
       "89   [[-8.8254, -3.0157], [-8.6264, -3.1479], [-8.4...   \n",
       "106  [[-4.663, 0.2311], [-4.4146, 0.2084], [-4.1654...   \n",
       "17   [[-1.0906, -0.3883], [-1.0729, -0.3721], [-1.0...   \n",
       "28   [[-9.5907, 0.4219], [-9.5869, 0.4193], [-9.586...   \n",
       "\n",
       "                                                 robot  \\\n",
       "73   [[0.7957, -0.6056], [0.8352, -0.55], [0.8352, ...   \n",
       "89   [[-0.743, 0.6693], [-0.9038, 0.4279], [-0.9644...   \n",
       "106  [[-0.9999, 0.0118], [-0.9931, 0.1176], [-0.999...   \n",
       "17   [[-0.7821, -0.6232], [-0.3819, -0.9242], [0.11...   \n",
       "28   [[0.6988, 0.7153], [0.3281, 0.9447], [-0.2224,...   \n",
       "\n",
       "                                              follower  \\\n",
       "73   [[-0.5891, 0.4541, 0.8234, -0.5675], [-0.6961,...   \n",
       "89   [[0.3299, -0.5874, -0.6815, 0.7318], [0.4846, ...   \n",
       "106  [[0.8749, 0.1223, -0.9962, -0.0871], [0.8366, ...   \n",
       "17   [[0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [...   \n",
       "28   [[-1.1599, -0.5517, -0.1146, -0.9934], [-0.706...   \n",
       "\n",
       "                                                nearby  competence  surprise  \\\n",
       "73   [[[-0.8485, 3.1467, 0.7937, -0.6083], [-1.3945...           2         3   \n",
       "89   [[[0.0, 0.0, -0.743, 0.6693], [0.0, 0.0, -0.90...           3         3   \n",
       "106  [[[0.0, 0.0, -0.9999, 0.0118], [0.0, 0.0, -0.9...           4         4   \n",
       "17   [[[0.0, 0.0, -0.7821, -0.6232], [0.0, 0.0, -0....           3         4   \n",
       "28   [[[-1.1599, -0.5517, -0.1146, -0.9934], [-0.70...           1         2   \n",
       "\n",
       "     intention  \n",
       "73           2  \n",
       "89           4  \n",
       "106          5  \n",
       "17           3  \n",
       "28           1  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# def get_examples(df, \n",
    "#                  positive_competence_count = 1, negative_competence_count = 1,\n",
    "#                  positive_surprise_count = 1, negative_surprise_count = 1,\n",
    "#                  positive_intention_count = 1, negative_intention_count = 1):\n",
    "#     # Filter samples based on the conditions\n",
    "#     competence_positive_idx = df[df['competence'].isin([3, 4, 5])].sample(n=positive_competence_count).index\n",
    "#     competence_negative_idx = df[df['competence'].isin([1, 2])].sample(n=negative_competence_count).index\n",
    "\n",
    "#     surprise_positive_idx = df[df['surprise'].isin([4, 5])].sample(n=positive_surprise_count).index\n",
    "#     surprise_negative_idx = df[df['surprise'].isin([1, 2, 3])].sample(n=negative_surprise_count).index\n",
    "\n",
    "#     intention_positive_idx = df[df['intention'].isin([3, 4, 5])].sample(n=positive_intention_count).index\n",
    "#     intention_negative_idx = df[df['intention'].isin([1, 2])].sample(n=negative_intention_count).index\n",
    "\n",
    "#     # Combine the filtered samples into one DataFrame\n",
    "#     selected_indices = pd.Index(list(set(competence_positive_idx) | set(competence_negative_idx) |\n",
    "#                                      set(surprise_positive_idx) | set(surprise_negative_idx) |\n",
    "#                                      set(intention_positive_idx) | set(intention_negative_idx)))\n",
    "\n",
    "#     # Create a DataFrame excluding the selected samples\n",
    "#     selected_samples = df.loc[selected_indices.unique()]\n",
    "#     remaining_samples = df.drop(selected_indices.unique())\n",
    "\n",
    "#     return selected_samples, remaining_samples\n",
    "\n",
    "def get_examples(df, count):\n",
    "    selected_samples = df.sample(n=count)\n",
    "    remaining_samples = df.drop(selected_samples.index)\n",
    "\n",
    "    return selected_samples, remaining_samples\n",
    "    # return df, None\n",
    "\n",
    "selected_samples, remaining_samples = get_examples(full_df, 80)\n",
    "selected_samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_query(row):\n",
    "    query = \"\"\n",
    "    query += \"Destination (8 timesteps, 2 features): \" + np.array2string(np.around(np.array(row[1].goal), decimals=4), separator=', ', max_line_width=np.inf).replace('\\n', '') + \"\\n\"\n",
    "    for i, nearby in enumerate(row[1].nearby):\n",
    "        query += \"Nearby pedestrian \" + str(i+1) + \" (8 timesteps, 4 features): \" + np.array2string(np.around(np.array(nearby), decimals=4), separator=', ', max_line_width=np.inf).replace('\\n', '') + \"\\n\"\n",
    "    if np.all(row[1].follower == 0):\n",
    "        query += \"Human Follower: Not detected\\n\"\n",
    "    else:\n",
    "        query += \"Human Follower (8 timesteps, 4 features): \" + np.array2string(np.around(np.array(row[1].follower), decimals=4), separator=', ', max_line_width=np.inf).replace('\\n', '') + \"\\n\"\n",
    "    query += \"Robot Orientation (8 timesteps, 2 features): \" + np.array2string(np.around(np.array(row[1].robot), decimals=4), separator=', ', max_line_width=np.inf).replace('\\n', '') + \"\\n\"\n",
    "    return query\n",
    "\n",
    "def parse_examples(rows):\n",
    "    examples = \"\"\n",
    "    for row in rows.iterrows():\n",
    "        example = \"\"\n",
    "        example += parse_query(row)\n",
    "        example += \"Grouth-Truth Ratings of Robot Performance in the time window: \" + str({\"competence\": row[1].competence, \"surprise\": row[1].surprise, \"intention\": row[1].intention})\n",
    "        examples += example + \"\\n\\n\"\n",
    "    \n",
    "    return examples\n",
    "\n",
    "text_examples = parse_examples(selected_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(general_examples, query):\n",
    "    general_text_examples = parse_examples(general_examples)\n",
    "\n",
    "    prompt = textwrap.dedent(f\"\"\"\\\n",
    "        A human followed a mobile robot while they navigated to a particular destination in an indoor environment.\n",
    "        During navigation, the human rated the robot's performance by answering three questions:\n",
    "        The first question is: 'How competent was the robot at navigating?'\n",
    "        The second question is: 'How surprising was the robot's navigation behavior?' and\n",
    "        The third question is: 'How clear were the robot's intentions during navigation?'\n",
    "        The human provided ratings for each of the questions as an integer between 1 and 5, where 1 was the lowest score and 5 was the highest.\n",
    "        For example, for the first question about competence, the ratings could be: 1 for 'incompetent', 2 for 'somewhat incompetent', 3 for 'neither competent nor incompetent', 4 for 'somewhat competent', and 5 for 'competent'.\n",
    "        For the second question about surprising navigation behavior, the ratings could be: 1 for 'predictable', 2 for 'somewhat predictable', 3 for 'neither predictable nor surprising', 4 for 'somewhat surprising', and 5 for 'surprising'.\n",
    "        Finally, for the third question about intention, the ratings could be: 1 for 'unclear intention', 2 for 'somewhat unclear intention', 3 for 'neither unclear nor clear intention', 4 for 'somewhat clear intention', and 5 for 'clear intention'.\n",
    "        \n",
    "        The robot has two Kinect cameras that can detect the poses of the people nearby in the robot coordinate system.\n",
    "        It can also detect the position of the destination relative to the robot. Below are the specifications of each type of feature detected at every timestep:\n",
    "        destination_position (x, y): the 2D position of the destination, relative to the robot's coordinate system.\n",
    "        follower_pose (x, y, cos(theta), sin(theta)): the position (x, y) and cos-sin encoding of orientation (cos(theta), sin(theta)) of the participant who followed the robot, relative to the robot's coordinate system.. If the follower is not detected at a timestep, all four values will be 0.\n",
    "        nearby_people_pose, a list of (x, y, cos(theta), sin(theta)): a list of positions (x, y) and cos-sin encodings of orientations (cos(theta), sin(theta)) of the nearby people around the robot, relative to the robot's coordinate system.\n",
    "        robot orientation (cos(theta), sin(theta)): the cos-sin encoding of the robot's orientation (cos(theta), sin(theta)) in the world coordinate system. All other features are in the robot coordinate system so we don't need to provide the robot's position.\n",
    "        \n",
    "        Each data example is a time window of 8 seconds, recorded at 1 hz, and resulting in 8 time-steps.\\n\"\"\")\n",
    "\n",
    "    if len(general_examples) > 0:\n",
    "        prompt += textwrap.dedent(f\"\"\"\\\n",
    "            Previously, we have gathered several data examples from different humans participating in the navigation task, which are given below and shuffled. For each example, you can see the ground-truth ratings that human provided to the robot in terms of the three questions about robot competence, surprising navigation behavior, and intention:\\n\\n{general_text_examples}\"\"\")\n",
    "    \n",
    "    prompt += textwrap.dedent(f\"\"\"\\\n",
    "        In the navigation task, the robot had three types of behaviors:\n",
    "        The first type of behavior is moving towards the destination: usually the absolute values of the x or y of the destination (relative to the robot) decrease over time (gets closer to 0),\n",
    "        The second type of behavior is rotating at a fixed position: usually causes the x and y of the destination (relative to the robot) to be almost unchanged, and the cos-sin encoding of the robot's orientation (cos(theta), sin(theta)) to change drastically over time, and\n",
    "        The third type of behavior is moving towards a wrong direction: usually causes the absolute values of the x or y of the destination (relative to the robot) to increase over time (get farther from 0).\n",
    "        In many cases, the moving towards the desintation corresponds to a high competence rating, low surprise rating, and high intention rating. Rotating at a fixed position and moving to a wrong direction usually corresponds to a lower competence rating, higher surprise rating, and lower intention rating.\"\"\")\n",
    "\n",
    "    prompt += textwrap.dedent(f\"\"\"\\\n",
    "            Now, by learning from the examples given by other previous participants, \"\"\")\n",
    "\n",
    "    prompt += textwrap.dedent(f\"\"\"\\ \n",
    "        can you check the following example given next by a new human and guess how this human would rate the robot's overall performance in the 8 seconds'?\\n{query}\n",
    "        Please return JSON containing your predicted ratings of robot's competence, surprise and clear intention in navigation using the following schema:\n",
    "        'competence': int, 'surprise': int, 'intention': int\n",
    "        Also, please provide explanations for your predictions.\n",
    "        Note that your prediction is about the robot's overall performance in the given time window. Remember that your responses must be integers between 1 and 5.\n",
    "        Based on our previous observation, people rarely choose to give a neutral rating of the robot's performance. \\n\"\"\")\n",
    "    \n",
    "    prompt += textwrap.dedent(f\"\"\"\\\n",
    "        Your predicted ratings of robot performance for the time window:\"\"\")\n",
    "    \n",
    "    return prompt\n",
    "    \n",
    "# import f1 score\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def compute_metrics(labeled_dataframe):\n",
    "    bin_acc_dict = {\n",
    "        'competence': {},\n",
    "        'surprise': {},\n",
    "        'intention': {}\n",
    "    }\n",
    "    bin_f1_dict = {\n",
    "        'competence': {},\n",
    "        'surprise': {},\n",
    "        'intention': {}\n",
    "    }\n",
    "    f1_dict = {\n",
    "        'competence': {},\n",
    "        'surprise': {},\n",
    "        'intention': {}\n",
    "    }\n",
    "\n",
    "    for num_examples in labeled_dataframe.num_examples.unique():\n",
    "        print(f\"\\nNumber of examples: {num_examples}\")\n",
    "        labeled_dataframe_subset = labeled_dataframe[labeled_dataframe.num_examples == num_examples]\n",
    "\n",
    "        for dimension in ['competence', 'surprise', 'intention']:\n",
    "            gt = labeled_dataframe_subset[dimension].tolist()\n",
    "            pt = labeled_dataframe_subset[f\"pt_{dimension}\"].tolist()\n",
    "\n",
    "            gt = np.array(gt) - 1\n",
    "            pt = np.array(pt) - 1\n",
    "\n",
    "            if dimension != 'surprise':\n",
    "                gt_binary = [1 if x <= 1 else 0 for x in gt]\n",
    "                pt_binary = [1 if x <= 1 else 0 for x in pt]\n",
    "            else:\n",
    "                gt_binary = [1 if x >= 3 else 0 for x in gt]\n",
    "                pt_binary = [1 if x >= 3 else 0 for x in pt]\n",
    "\n",
    "            print(\"gt_binary\", gt_binary)\n",
    "            print(\"pt_binary\", pt_binary)\n",
    "\n",
    "            f1 = f1_score(gt, pt, average=\"macro\", zero_division=0)\n",
    "            bin_f1 = f1_score(gt_binary, pt_binary)\n",
    "            bin_acc = accuracy_score(gt_binary, pt_binary)\n",
    "            mae = np.abs(gt - pt).mean()\n",
    "            print(f\"F1 score for {dimension}, {num_examples} examples: {f1:.4f}\")\n",
    "            print(f\"Binary F1 score for {dimension}, {num_examples} examples: {bin_f1:.4f}\")\n",
    "            print(f\"Binary Accuracy for {dimension}, {num_examples} examples: {bin_acc:.4f}\")\n",
    "            print(f\"MAE for {dimension}, {num_examples} examples: {mae:.4f}\")\n",
    "\n",
    "            f1_dict[dimension][num_examples] = f1\n",
    "            bin_f1_dict[dimension][num_examples] = bin_f1\n",
    "            bin_acc_dict[dimension][num_examples] = bin_acc\n",
    "            \n",
    "    return f1_dict, bin_f1_dict, bin_acc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_examples = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant: 1713303216.8060517\n",
      "Example 1 / 109\n",
      "Ground Truth:\n",
      "(4, 2, 4)\n",
      "\n",
      "Result:\n",
      "{'competence': 3, 'surprise': 3, 'intention': 3}\n",
      "\n",
      "Example 2 / 109\n",
      "Ground Truth:\n",
      "(4, 4, 4)\n",
      "\n",
      "Result:\n",
      "{'competence': 2, 'surprise': 4, 'intention': 2}\n",
      "\n",
      "Example 3 / 109\n",
      "Ground Truth:\n",
      "(4, 4, 4)\n",
      "\n",
      "The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Example 3 / 109\n",
      "Ground Truth:\n",
      "(4, 4, 5)\n",
      "\n",
      "Result:\n",
      "{'competence': 4, 'surprise': 2, 'intention': 4}\n",
      "\n",
      "Participant: 1715357694.9017513\n",
      "Example 4 / 109\n",
      "Ground Truth:\n",
      "(1, 5, 1)\n",
      "\n",
      "Result:\n",
      "{'competence': 2, 'surprise': 4, 'intention': 2}\n",
      "\n",
      "Example 5 / 109\n",
      "Ground Truth:\n",
      "(1, 5, 1)\n",
      "\n",
      "Result:\n",
      "{'competence': 2, 'surprise': 4, 'intention': 2}\n",
      "\n",
      "Example 6 / 109\n",
      "Ground Truth:\n",
      "(5, 5, 5)\n",
      "\n",
      "Result:\n",
      "{'competence': 4, 'surprise': 2, 'intention': 4}\n",
      "\n",
      "Example 7 / 109\n",
      "Ground Truth:\n",
      "(2, 4, 2)\n",
      "\n",
      "Result:\n",
      "{'competence': 2, 'surprise': 4, 'intention': 2}\n",
      "\n",
      "Example 8 / 109\n",
      "Ground Truth:\n",
      "(3, 3, 1)\n",
      "\n",
      "Result:\n",
      "{'competence': 2, 'surprise': 4, 'intention': 2}\n",
      "\n",
      "Example 9 / 109\n",
      "Ground Truth:\n",
      "(4, 4, 4)\n",
      "\n",
      "Result:\n",
      "{'competence': 4, 'surprise': 2, 'intention': 4}\n",
      "\n",
      "Participant: 1713301481.745976\n",
      "Example 10 / 109\n",
      "Ground Truth:\n",
      "(5, 2, 5)\n",
      "\n",
      "Result:\n",
      "{'competence': 4, 'surprise': 3, 'intention': 4}\n",
      "\n",
      "Example 11 / 109\n",
      "Ground Truth:\n",
      "(1, 3, 2)\n",
      "\n",
      "The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Example 11 / 109\n",
      "Ground Truth:\n",
      "(4, 3, 4)\n",
      "\n",
      "Result:\n",
      "{'competence': 2, 'surprise': 4, 'intention': 2}\n",
      "\n",
      "Example 12 / 109\n",
      "Ground Truth:\n",
      "(5, 1, 5)\n",
      "\n",
      "Result:\n",
      "{'competence': 4, 'surprise': 3, 'intention': 4}\n",
      "\n",
      "Example 13 / 109\n",
      "Ground Truth:\n",
      "(1, 5, 1)\n",
      "\n",
      "Result:\n",
      "{'competence': 2, 'surprise': 4, 'intention': 2}\n",
      "\n",
      "Example 14 / 109\n",
      "Ground Truth:\n",
      "(1, 4, 1)\n",
      "\n",
      "Result:\n",
      "{'competence': 2, 'surprise': 4, 'intention': 2}\n",
      "\n",
      "Example 15 / 109\n",
      "Ground Truth:\n",
      "(4, 4, 5)\n",
      "\n",
      "Result:\n",
      "{'competence': 4, 'surprise': 2, 'intention': 4}\n",
      "\n",
      "Example 16 / 109\n",
      "Ground Truth:\n",
      "(5, 4, 5)\n",
      "\n",
      "Result:\n",
      "{'competence': 2, 'surprise': 4, 'intention': 2}\n",
      "\n",
      "Participant: 1713302818.578851\n",
      "Example 17 / 109\n",
      "Ground Truth:\n",
      "(4, 2, 4)\n",
      "\n",
      "Result:\n",
      "{'competence': 2, 'surprise': 4, 'intention': 1}\n",
      "\n",
      "Example 18 / 109\n",
      "Ground Truth:\n",
      "(4, 2, 4)\n",
      "\n",
      "Result:\n",
      "{'competence': 2, 'surprise': 4, 'intention': 2}\n",
      "\n",
      "Example 19 / 109\n",
      "Ground Truth:\n",
      "(4, 2, 4)\n",
      "\n",
      "Result:\n",
      "{'competence': 2, 'surprise': 3, 'intention': 2}\n",
      "\n",
      "Example 20 / 109\n",
      "Ground Truth:\n",
      "(5, 2, 4)\n",
      "\n",
      "Result:\n",
      "{'competence': 4, 'surprise': 2, 'intention': 4}\n",
      "\n",
      "Example 21 / 109\n",
      "Ground Truth:\n",
      "(3, 4, 3)\n",
      "\n",
      "Result:\n",
      "{'competence': 2, 'surprise': 4, 'intention': 2}\n",
      "\n",
      "Example 22 / 109\n",
      "Ground Truth:\n",
      "(2, 4, 2)\n",
      "\n",
      "Result:\n",
      "{'competence': 2, 'surprise': 4, 'intention': 2}\n",
      "\n",
      "Example 23 / 109\n",
      "Ground Truth:\n",
      "(4, 2, 4)\n",
      "\n",
      "Result:\n",
      "{'competence': 4, 'surprise': 2, 'intention': 4}\n",
      "\n",
      "Participant: 1713204524.642894\n",
      "Example 24 / 109\n",
      "Ground Truth:\n",
      "(1, 1, 5)\n",
      "\n",
      "Result:\n",
      "{'competence': 2, 'surprise': 3, 'intention': 2}\n",
      "\n",
      "Example 25 / 109\n",
      "Ground Truth:\n",
      "(1, 4, 1)\n",
      "\n",
      "Result:\n",
      "{'competence': 1, 'surprise': 4, 'intention': 1}\n",
      "\n",
      "Example 26 / 109\n",
      "Ground Truth:\n",
      "(5, 1, 4)\n",
      "\n",
      "Result:\n",
      "{'competence': 4, 'surprise': 2, 'intention': 4}\n",
      "\n",
      "Example 27 / 109\n",
      "Ground Truth:\n",
      "(4, 4, 2)\n",
      "\n",
      "Result:\n",
      "{'competence': 2, 'surprise': 4, 'intention': 2}\n",
      "\n",
      "Example 28 / 109\n",
      "Ground Truth:\n",
      "(1, 5, 2)\n",
      "\n",
      "Result:\n",
      "{'competence': 2, 'surprise': 4, 'intention': 2}\n",
      "\n",
      "Example 29 / 109\n",
      "Ground Truth:\n",
      "(2, 4, 3)\n",
      "\n",
      "Result:\n",
      "{'competence': 4, 'surprise': 2, 'intention': 4}\n",
      "\n",
      "Example 30 / 109\n",
      "Ground Truth:\n",
      "(5, 1, 5)\n",
      "\n",
      "Result:\n",
      "{'competence': 4, 'surprise': 3, 'intention': 3}\n",
      "\n",
      "Participant: 1715274983.243521\n",
      "Example 31 / 109\n",
      "Ground Truth:\n",
      "(5, 2, 4)\n",
      "\n",
      "Result:\n",
      "{'competence': 4, 'surprise': 2, 'intention': 4}\n",
      "\n",
      "Example 32 / 109\n",
      "Ground Truth:\n",
      "(1, 5, 1)\n",
      "\n",
      "Result:\n",
      "{'competence': 3, 'surprise': 3, 'intention': 3}\n",
      "\n",
      "Example 33 / 109\n",
      "Ground Truth:\n",
      "(2, 4, 2)\n",
      "\n",
      "Result:\n",
      "{'competence': 2, 'surprise': 4, 'intention': 2}\n",
      "\n",
      "Example 34 / 109\n",
      "Ground Truth:\n",
      "(2, 2, 3)\n",
      "\n",
      "Result:\n",
      "{'competence': 4, 'surprise': 3, 'intention': 4}\n",
      "\n",
      "Participant: 1713393153.5699694\n",
      "Example 35 / 109\n",
      "Ground Truth:\n",
      "(1, 4, 2)\n",
      "\n",
      "Result:\n",
      "{'competence': 4, 'surprise': 2, 'intention': 4}\n",
      "\n",
      "Example 36 / 109\n",
      "Ground Truth:\n",
      "(2, 3, 2)\n",
      "\n",
      "Result:\n",
      "{'competence': 2, 'surprise': 4, 'intention': 1}\n",
      "\n",
      "Example 37 / 109\n",
      "Ground Truth:\n",
      "(3, 3, 4)\n",
      "\n",
      "Result:\n",
      "{'competence': 4, 'surprise': 2, 'intention': 4}\n",
      "\n",
      "Example 38 / 109\n",
      "Ground Truth:\n",
      "(2, 4, 1)\n",
      "\n",
      "Result:\n",
      "{'competence': 2, 'surprise': 4, 'intention': 2}\n",
      "\n",
      "Example 39 / 109\n",
      "Ground Truth:\n",
      "(1, 5, 1)\n",
      "\n",
      "Result:\n",
      "{'competence': 2, 'surprise': 4, 'intention': 2}\n",
      "\n",
      "Example 40 / 109\n",
      "Ground Truth:\n",
      "(1, 4, 1)\n",
      "\n",
      "Result:\n",
      "{'competence': 4, 'surprise': 2, 'intention': 4}\n",
      "\n",
      "Participant: 1713203589.8971455\n",
      "Example 41 / 109\n",
      "Ground Truth:\n",
      "(2, 1, 2)\n",
      "\n",
      "Result:\n",
      "{'competence': 4, 'surprise': 2, 'intention': 4}\n",
      "\n",
      "Example 42 / 109\n",
      "Ground Truth:\n",
      "(3, 2, 1)\n",
      "\n",
      "Result:\n",
      "{'competence': 1, 'surprise': 3, 'intention': 2}\n",
      "\n",
      "Example 43 / 109\n",
      "Ground Truth:\n",
      "(3, 4, 1)\n",
      "\n",
      "Result:\n",
      "{'competence': 2, 'surprise': 3, 'intention': 2}\n",
      "\n",
      "Example 44 / 109\n",
      "Ground Truth:\n",
      "(2, 3, 1)\n",
      "\n",
      "Result:\n",
      "{'competence': 4, 'surprise': 2, 'intention': 4}\n",
      "\n",
      "Example 45 / 109\n",
      "Ground Truth:\n",
      "(3, 4, 1)\n",
      "\n",
      "Result:\n",
      "{'competence': 2, 'surprise': 4, 'intention': 2}\n",
      "\n",
      "Example 46 / 109\n",
      "Ground Truth:\n",
      "(2, 4, 1)\n",
      "\n",
      "Result:\n",
      "{'competence': 1, 'surprise': 4, 'intention': 1}\n",
      "\n",
      "Example 47 / 109\n",
      "Ground Truth:\n",
      "(2, 4, 1)\n",
      "\n",
      "Result:\n",
      "{'competence': 4, 'surprise': 2, 'intention': 4}\n",
      "\n",
      "Example 48 / 109\n",
      "Ground Truth:\n",
      "(2, 2, 1)\n",
      "\n",
      "Result:\n",
      "{'competence': 4, 'surprise': 2, 'intention': 4}\n",
      "\n",
      "Participant: 1713201977.550016\n",
      "Example 49 / 109\n",
      "Ground Truth:\n",
      "(1, 1, 2)\n",
      "\n",
      "Result:\n",
      "{'competence': 2, 'surprise': 4, 'intention': 1}\n",
      "\n",
      "Example 50 / 109\n",
      "Ground Truth:\n",
      "(2, 2, 2)\n",
      "\n",
      "Result:\n",
      "{'competence': 2, 'surprise': 4, 'intention': 2}\n",
      "\n",
      "Participant: 1713395481.0340421\n",
      "Example 51 / 109\n",
      "Ground Truth:\n",
      "(5, 2, 5)\n",
      "\n",
      "Result:\n",
      "{'competence': 4, 'surprise': 2, 'intention': 4}\n",
      "\n",
      "Example 52 / 109\n",
      "Ground Truth:\n",
      "(1, 5, 1)\n",
      "\n",
      "Result:\n",
      "{'competence': 4, 'surprise': 2, 'intention': 4}\n",
      "\n",
      "Example 53 / 109\n",
      "Ground Truth:\n",
      "(2, 4, 4)\n",
      "\n",
      "Result:\n",
      "{'competence': 2, 'surprise': 4, 'intention': 2}\n",
      "\n",
      "Example 54 / 109\n",
      "Ground Truth:\n",
      "(4, 3, 4)\n",
      "\n",
      "Result:\n",
      "{'competence': 4, 'surprise': 2, 'intention': 4}\n",
      "\n",
      "Example 55 / 109\n",
      "Ground Truth:\n",
      "(1, 5, 1)\n",
      "\n",
      "Result:\n",
      "{'competence': 2, 'surprise': 4, 'intention': 2}\n",
      "\n",
      "Example 56 / 109\n",
      "Ground Truth:\n",
      "(1, 5, 1)\n",
      "\n",
      "Result:\n",
      "{'competence': 2, 'surprise': 4, 'intention': 3}\n",
      "\n",
      "Example 57 / 109\n",
      "Ground Truth:\n",
      "(2, 4, 2)\n",
      "\n",
      "Result:\n",
      "{'competence': 4, 'surprise': 3, 'intention': 4}\n",
      "\n",
      "Participant: 1713543095.55775\n",
      "Example 58 / 109\n",
      "Ground Truth:\n",
      "(4, 3, 4)\n",
      "\n",
      "Result:\n",
      "{'competence': 2, 'surprise': 4, 'intention': 2}\n",
      "\n",
      "Example 59 / 109\n",
      "Ground Truth:\n",
      "(3, 4, 2)\n",
      "\n",
      "Result:\n",
      "{'competence': 2, 'surprise': 4, 'intention': 2}\n",
      "\n",
      "Example 60 / 109\n",
      "Ground Truth:\n",
      "(3, 2, 1)\n",
      "\n",
      "Result:\n",
      "{'competence': 2, 'surprise': 3, 'intention': 2}\n",
      "\n",
      "Example 61 / 109\n",
      "Ground Truth:\n",
      "(2, 2, 2)\n",
      "\n",
      "Result:\n",
      "{'competence': 4, 'surprise': 2, 'intention': 4}\n",
      "\n",
      "Example 62 / 109\n",
      "Ground Truth:\n",
      "(4, 4, 4)\n",
      "\n",
      "Result:\n",
      "{'competence': 3, 'surprise': 3, 'intention': 3}\n",
      "\n",
      "Example 63 / 109\n",
      "Ground Truth:\n",
      "(4, 5, 2)\n",
      "\n",
      "Result:\n",
      "{'competence': 2, 'surprise': 4, 'intention': 1}\n",
      "\n",
      "Example 64 / 109\n",
      "Ground Truth:\n",
      "(2, 4, 2)\n",
      "\n",
      "Result:\n",
      "{'competence': 4, 'surprise': 2, 'intention': 4}\n",
      "\n",
      "Participant: 1713291823.9341214\n",
      "Example 65 / 109\n",
      "Ground Truth:\n",
      "(5, 2, 4)\n",
      "\n",
      "500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting\n",
      "Example 65 / 109\n",
      "Ground Truth:\n",
      "(4, 4, 2)\n",
      "\n",
      "Result:\n",
      "{'competence': 2, 'surprise': 3, 'intention': 2}\n",
      "\n",
      "Example 66 / 109\n",
      "Ground Truth:\n",
      "(5, 2, 4)\n",
      "\n",
      "Result:\n",
      "{'competence': 4, 'surprise': 2, 'intention': 4}\n",
      "\n",
      "Example 67 / 109\n",
      "Ground Truth:\n",
      "(4, 4, 5)\n",
      "\n",
      "Result:\n",
      "{'competence': 4, 'surprise': 3, 'intention': 4}\n",
      "\n",
      "Example 68 / 109\n",
      "Ground Truth:\n",
      "(4, 4, 4)\n",
      "\n",
      "Result:\n",
      "{'competence': 1, 'surprise': 4, 'intention': 1}\n",
      "\n",
      "Example 69 / 109\n",
      "Ground Truth:\n",
      "(4, 4, 3)\n",
      "\n",
      "Result:\n",
      "{'competence': 4, 'surprise': 2, 'intention': 4}\n",
      "\n",
      "Participant: 1713541727.5521238\n",
      "Example 70 / 109\n",
      "Ground Truth:\n",
      "(1, 5, 1)\n",
      "\n",
      "Result:\n",
      "{'competence': 2, 'surprise': 4, 'intention': 1}\n",
      "\n",
      "Example 71 / 109\n",
      "Ground Truth:\n",
      "(2, 3, 2)\n",
      "\n",
      "Result:\n",
      "{'competence': 2, 'surprise': 3, 'intention': 2}\n",
      "\n",
      "Example 72 / 109\n",
      "Ground Truth:\n",
      "(4, 2, 5)\n",
      "\n",
      "Result:\n",
      "{'competence': 4, 'surprise': 2, 'intention': 4}\n",
      "\n",
      "Example 73 / 109\n",
      "Ground Truth:\n",
      "(2, 5, 2)\n",
      "\n",
      "Result:\n",
      "{'competence': 4, 'surprise': 2, 'intention': 4}\n",
      "\n",
      "Example 74 / 109\n",
      "Ground Truth:\n",
      "(1, 5, 1)\n",
      "\n",
      "Result:\n",
      "{'competence': 3, 'surprise': 3, 'intention': 3}\n",
      "\n",
      "Example 75 / 109\n",
      "Ground Truth:\n",
      "(1, 5, 1)\n",
      "\n",
      "Result:\n",
      "{'competence': 2, 'surprise': 4, 'intention': 2}\n",
      "\n",
      "Participant: 1713300855.2562926\n",
      "Example 76 / 109\n",
      "Ground Truth:\n",
      "(1, 1, 1)\n",
      "\n",
      "Result:\n",
      "{'competence': 2, 'surprise': 4, 'intention': 2}\n",
      "\n",
      "Example 77 / 109\n",
      "Ground Truth:\n",
      "(1, 5, 1)\n",
      "\n",
      "Result:\n",
      "{'competence': 2, 'surprise': 4, 'intention': 2}\n",
      "\n",
      "Example 78 / 109\n",
      "Ground Truth:\n",
      "(4, 2, 4)\n",
      "\n",
      "Result:\n",
      "{'competence': 2, 'surprise': 4, 'intention': 2}\n",
      "\n",
      "Participant: 1713293186.7886262\n",
      "Example 79 / 109\n",
      "Ground Truth:\n",
      "(5, 3, 4)\n",
      "\n",
      "Result:\n",
      "{'competence': 4, 'surprise': 2, 'intention': 4}\n",
      "\n",
      "Participant: 1713540083.376075\n",
      "Example 80 / 109\n",
      "Ground Truth:\n",
      "(5, 4, 5)\n",
      "\n",
      "Result:\n",
      "{'competence': 2, 'surprise': 4, 'intention': 2}\n",
      "\n",
      "Example 81 / 109\n",
      "Ground Truth:\n",
      "(5, 4, 5)\n",
      "\n",
      "Result:\n",
      "{'competence': 2, 'surprise': 4, 'intention': 2}\n",
      "\n",
      "Example 82 / 109\n",
      "Ground Truth:\n",
      "(5, 2, 5)\n",
      "\n",
      "Result:\n",
      "{'competence': 4, 'surprise': 2, 'intention': 4}\n",
      "\n",
      "Example 83 / 109\n",
      "Ground Truth:\n",
      "(5, 5, 5)\n",
      "\n",
      "Result:\n",
      "{'competence': 3, 'surprise': 3, 'intention': 3}\n",
      "\n",
      "Example 84 / 109\n",
      "Ground Truth:\n",
      "(5, 4, 4)\n",
      "\n",
      "Result:\n",
      "{'competence': 2, 'surprise': 4, 'intention': 2}\n",
      "\n",
      "Example 85 / 109\n",
      "Ground Truth:\n",
      "(5, 5, 5)\n",
      "\n",
      "Result:\n",
      "{'competence': 2, 'surprise': 4, 'intention': 2}\n",
      "\n",
      "Participant: 1713205927.3139355\n",
      "Example 86 / 109\n",
      "Ground Truth:\n",
      "(4, 4, 2)\n",
      "\n",
      "Result:\n",
      "{'competence': 4, 'surprise': 2, 'intention': 4}\n",
      "\n",
      "Example 87 / 109\n",
      "Ground Truth:\n",
      "(4, 4, 2)\n",
      "\n",
      "Result:\n",
      "{'competence': 3, 'surprise': 3, 'intention': 3}\n",
      "\n",
      "Example 88 / 109\n",
      "Ground Truth:\n",
      "(5, 1, 5)\n",
      "\n",
      "Result:\n",
      "{'competence': 2, 'surprise': 3, 'intention': 2}\n",
      "\n",
      "Participant: 1715356072.5795307\n",
      "Example 89 / 109\n",
      "Ground Truth:\n",
      "(1, 2, 1)\n",
      "\n",
      "Result:\n",
      "{'competence': 2, 'surprise': 4, 'intention': 2}\n",
      "\n",
      "Example 90 / 109\n",
      "Ground Truth:\n",
      "(2, 2, 1)\n",
      "\n",
      "Result:\n",
      "{'competence': 3, 'surprise': 3, 'intention': 3}\n",
      "\n",
      "Example 91 / 109\n",
      "Ground Truth:\n",
      "(4, 4, 5)\n",
      "\n",
      "Result:\n",
      "{'competence': 4, 'surprise': 2, 'intention': 4}\n",
      "\n",
      "Example 92 / 109\n",
      "Ground Truth:\n",
      "(2, 3, 2)\n",
      "\n",
      "Result:\n",
      "{'competence': 3, 'surprise': 3, 'intention': 2}\n",
      "\n",
      "Example 93 / 109\n",
      "Ground Truth:\n",
      "(2, 4, 2)\n",
      "\n",
      "Result:\n",
      "{'competence': 4, 'surprise': 2, 'intention': 4}\n",
      "\n",
      "Example 94 / 109\n",
      "Ground Truth:\n",
      "(1, 2, 2)\n",
      "\n",
      "Result:\n",
      "{'competence': 2, 'surprise': 4, 'intention': 2}\n",
      "\n",
      "Participant: 1713303711.6696327\n",
      "Example 95 / 109\n",
      "Ground Truth:\n",
      "(4, 2, 4)\n",
      "\n",
      "The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Example 95 / 109\n",
      "Ground Truth:\n",
      "(4, 4, 5)\n",
      "\n",
      "Result:\n",
      "{'competence': 2, 'surprise': 4, 'intention': 1}\n",
      "\n",
      "Example 96 / 109\n",
      "Ground Truth:\n",
      "(5, 5, 5)\n",
      "\n",
      "Result:\n",
      "{'competence': 4, 'surprise': 2, 'intention': 4}\n",
      "\n",
      "Example 97 / 109\n",
      "Ground Truth:\n",
      "(3, 3, 3)\n",
      "\n",
      "Result:\n",
      "{'competence': 3, 'surprise': 3, 'intention': 2}\n",
      "\n",
      "Example 98 / 109\n",
      "Ground Truth:\n",
      "(4, 3, 4)\n",
      "\n",
      "The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Example 98 / 109\n",
      "Ground Truth:\n",
      "(4, 4, 5)\n",
      "\n",
      "Result:\n",
      "{'competence': 4, 'surprise': 2, 'intention': 4}\n",
      "\n",
      "Example 99 / 109\n",
      "Ground Truth:\n",
      "(5, 5, 5)\n",
      "\n",
      "Result:\n",
      "{'competence': 4, 'surprise': 2, 'intention': 4}\n",
      "\n",
      "Participant: 1713299415.192685\n",
      "Example 100 / 109\n",
      "Ground Truth:\n",
      "(2, 5, 1)\n",
      "\n",
      "Result:\n",
      "{'competence': 4, 'surprise': 2, 'intention': 4}\n",
      "\n",
      "Participant: 1713287635.6692748\n",
      "Example 101 / 109\n",
      "Ground Truth:\n",
      "(5, 5, 3)\n",
      "\n",
      "Result:\n",
      "{'competence': 4, 'surprise': 2, 'intention': 4}\n",
      "\n",
      "Participant: 1713301177.7696\n",
      "Example 102 / 109\n",
      "Ground Truth:\n",
      "(4, 2, 4)\n",
      "\n",
      "Result:\n",
      "{'competence': 4, 'surprise': 2, 'intention': 4}\n",
      "\n",
      "Participant: 1713302125.87454\n",
      "Example 103 / 109\n",
      "Ground Truth:\n",
      "(4, 4, 2)\n",
      "\n",
      "Result:\n",
      "{'competence': 2, 'surprise': 4, 'intention': 1}\n",
      "\n",
      "Participant: 1713110825.4897027\n",
      "Example 104 / 109\n",
      "Ground Truth:\n",
      "(5, 4, 1)\n",
      "\n",
      "Result:\n",
      "{'competence': 4, 'surprise': 2, 'intention': 4}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "\n",
    "labeled_rows = []\n",
    "classifiers = []\n",
    "used_examples = []\n",
    "curr_count = 0\n",
    "\n",
    "for particpant in full_df.participant.unique():\n",
    "    print(f\"Participant: {particpant}\")\n",
    "    \n",
    "    participant_df = full_df[full_df.participant == particpant]\n",
    "    non_participant_df = full_df[full_df.participant != particpant]\n",
    "    # sort by id\n",
    "    participant_df = participant_df.sort_values(by='id')\n",
    "\n",
    "    for i in range(len(participant_df)):\n",
    "        print(f\"Example {curr_count+1} / {len(full_df)}\")\n",
    "        \n",
    "        next_example = participant_df.iloc[i]\n",
    "        next_example = (next_example.name, next_example)\n",
    "\n",
    "        general_selected_examples, general_remaining_examples = get_examples(non_participant_df, bootstrap_examples)\n",
    "\n",
    "        query = parse_query(next_example)\n",
    "        prompt = build_prompt(general_selected_examples, query)\n",
    "\n",
    "        # print(f\"Query:\\n{query}\")\n",
    "        print(f\"Ground Truth:\\n{next_example[1].competence, next_example[1].surprise, next_example[1].intention}\\n\")\n",
    "\n",
    "        try:\n",
    "            result = model.generate_content(prompt)\n",
    "            # print(result.text + '\\n')\n",
    "            result_json = json.loads(\"{\" + result.text.replace(\"'\", '\"').split(\"{\")[1].rsplit(\"}\")[0] + \"}\")\n",
    "            print(f\"Result:\\n{result_json}\\n\")\n",
    "            \n",
    "            new_row = next_example[1].to_dict().copy()\n",
    "            new_row[\"pt_competence\"] = result_json[\"competence\"]\n",
    "            new_row[\"pt_surprise\"] = result_json[\"surprise\"]\n",
    "            new_row[\"pt_intention\"] = result_json[\"intention\"]\n",
    "            \n",
    "            new_row[\"personalize_examples\"] = i\n",
    "            new_row['bootstrap_examples'] = bootstrap_examples\n",
    "\n",
    "            new_row[\"bin_gt_competence\"] = 1 if int(new_row[\"competence\"]) <= 2 else 0\n",
    "            new_row[\"bin_gt_surprise\"] = 1 if int(new_row[\"surprise\"]) >= 4 else 0\n",
    "            new_row[\"bin_gt_intention\"] = 1 if int(new_row[\"intention\"]) <= 2 else 0\n",
    "\n",
    "            new_row[\"bin_pt_competence\"] = 1 if int(new_row[\"pt_competence\"]) <= 2 else 0\n",
    "            new_row[\"bin_pt_surprise\"] = 1 if int(new_row[\"pt_surprise\"]) >= 4 else 0\n",
    "            new_row[\"bin_pt_intention\"] = 1 if int(new_row[\"pt_intention\"]) <= 2 else 0\n",
    "\n",
    "            new_row[\"bin_correct_competence\"] = int(new_row[\"bin_gt_competence\"] == new_row[\"bin_pt_competence\"])\n",
    "            new_row[\"bin_correct_surprise\"] = int(new_row[\"bin_gt_surprise\"] == new_row[\"bin_pt_surprise\"])\n",
    "            new_row[\"bin_correct_intention\"] = int(new_row[\"bin_gt_intention\"] == new_row[\"bin_pt_intention\"])\n",
    "\n",
    "            labeled_rows.append(new_row)\n",
    "            sleep(5)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            sleep(5)\n",
    "            continue\n",
    "\n",
    "        curr_count += 1\n",
    "        labeled_dataframe = pd.DataFrame(labeled_rows)\n",
    "        labeled_dataframe['model'] = 'LLM'\n",
    "        labeled_dataframe.rename(columns={\"competence\": \"gt_competence\", \"surprise\": \"gt_surprise\", \"intention\": \"gt_intention\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_dataframe = pd.DataFrame(labeled_rows)\n",
    "labeled_dataframe.to_csv(\"/data/llm_RQ1_kenneth.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5673076923076923\n",
      "0.5961538461538461\n",
      "0.625\n",
      "0.5287037037037036 0.34344351027845405\n"
     ]
    }
   ],
   "source": [
    "labeled_dataframe = pd.read_csv(\"/data/llm_RQ1_kenneth.csv\")\n",
    "\n",
    "for dimension in ['competence', 'surprise', 'intention']:\n",
    "    print(dimension, \"overall accuracy:\", labeled_dataframe[f'bin_correct_{dimension}'].mean())\n",
    "    bin_f1s = []\n",
    "    bin_accs = []\n",
    "    for participant in labeled_dataframe.participant.unique():\n",
    "        participant_df = labeled_dataframe[labeled_dataframe.participant == participant]\n",
    "        bin_f1 = f1_score(participant_df[f'bin_gt_{dimension}'], participant_df[f'bin_pt_{dimension}'], zero_division=1)\n",
    "        bin_acc = accuracy_score(participant_df[f'bin_gt_{dimension}'], participant_df[f'bin_pt_{dimension}'])\n",
    "        bin_f1s.append(bin_f1)  \n",
    "        bin_accs.append(bin_acc)\n",
    "\n",
    "    print(dimension, \"average f1:\", np.mean(bin_f1s), np.std(bin_f1s))\n",
    "    print(dimension, \"average acc:\", np.mean(bin_accs), np.std(bin_accs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
